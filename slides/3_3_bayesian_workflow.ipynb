{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d908d891",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What could go wrong and how to fix it\n",
    "\n",
    "## 2. Take a step back: look at the full Bayesian workflow\n",
    "<img src=\"figures/what-if-i-told-you-this-is-not-fully-bayesian.jpg\" align=\"center\" alt=\"beadexample\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0396c7d3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Outline\n",
    "\n",
    "1) Model misspecification\n",
    "\n",
    "2) Bayesian workflow\n",
    "\n",
    "3) Bayesian workflow in `sbi`\n",
    "\n",
    "4) Simulation-based calibration\n",
    "\n",
    "5) Practical: Bayesian workflow in `sbi`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab124b32",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Model misspecification\n",
    "\n",
    "- previous session: troubleshooting with the `sbi` package with **given** simulator and prior\n",
    "- what if the model and prior are not accurately modelling the observed data $x_o$\n",
    "\n",
    "- what if the model is **misspecified**?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fac140",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Model misspecification example\n",
    "\n",
    "- the prior and simulator do not capture the actual data generating process\n",
    "- $x_o$ is not in the prior predictive distribution\n",
    "\n",
    "\n",
    "- prior predictive distribution\n",
    "    - all data the model can generate: $(\\theta, x) \\sim p(\\theta, x) = p(x | \\theta)p(\\theta)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cfd3f5",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from sbi.inference import SNLE, SNPE, prepare_for_sbi, simulate_for_sbi\n",
    "from sbi.simulators.linear_gaussian import (\n",
    "    linear_gaussian,\n",
    "    samples_true_posterior_linear_gaussian_uniform_prior,\n",
    ")\n",
    "import torch\n",
    "from sbi.utils import BoxUniform\n",
    "import matplotlib.pyplot as plt\n",
    "from sbi.analysis import pairplot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b2631b",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Model misspecification example\n",
    "\n",
    "$$\n",
    "\\text{prior:  } \\theta \\sim \\mathcal{N}(0, I) \\\\\n",
    "\\text{simulator:  } x \\sim \\mathcal{N}(\\theta, I) \\\\\n",
    "\\\\\n",
    "\\text{but:  } x_o \\sim \\mathcal{N}(\\theta_o, 5 * I)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551ac16b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Gaussian simulator\n",
    "def simulator(theta, scale=0.5, num_samples=100):\n",
    "    # Sample from standard normal, shift with mean.\n",
    "    return scale * torch.randn(theta.shape) + theta\n",
    "\n",
    "num_dim = 3\n",
    "# Misspecification.\n",
    "simulator_scale = 0.1\n",
    "true_scale = 5.0\n",
    "\n",
    "# Uniform prior.\n",
    "prior = torch.distributions.MultivariateNormal(torch.zeros(num_dim), 2 * torch.eye(num_dim))\n",
    "x_o = simulator(prior.sample((1,)), scale=true_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ac25c8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Model misspecification: $x_o$ not in prior predictive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77246cc",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pairplot(simulator(prior.sample((1000,)), scale=simulator_scale), \n",
    "         upper=\"scatter\", points=x_o, points_colors=\"k\", limits=[[-10, 10]], \n",
    "         labels=[f\"$x_{ii}$\" for ii in range(num_dim)]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1410be0d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Other examples of model misspecification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5349e28e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- what we have here: one hyper-parameter (scale) of the simulator misspecified \n",
    "    - inference with `sbi` can fail or be biased (ongoing research)\n",
    "    - not enough training data around parameters relevant for `x_o`\n",
    "    - density-estimator ill-behaved when evaluated at `x_o`\n",
    "- more severe: wrong model class\n",
    "- prior misspecification\n",
    "- do you know more examples? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76997e04",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bayesian inference vs. Bayesian workflow\n",
    "\n",
    "- Bayesian inference: \n",
    "    - obtain posterior\n",
    "    - (or samples)\n",
    "- Bayesian workflow:\n",
    "    - model building\n",
    "    - inference\n",
    "    - model checking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb51f6b",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"figures/bayesian_worklow_chart.png\" align=\"center\" alt=\"beadexample\" width=\"800\"/> \n",
    "[Gelman et al. 2020]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe81b5bd",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Recommended reading\n",
    "\n",
    "- Gelman et al. 2020, \"Bayesian workflow\", \n",
    "https://arxiv.org/abs/2011.01808\n",
    "\n",
    "- Michael Betancourt, \"Towards a principled Bayesian Workflow\", 2020\n",
    "https://betanalpha.github.io/assets/case_studies/principled_bayesian_workflow.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be52344",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## Bayesian workflow in `sbi`\n",
    "\n",
    "Which of the steps can we do in `sbi` (until now)?\n",
    "\n",
    "- prior predictive checks\n",
    "- convergence diagnostics (training logs)\n",
    "- posterior predictive checks\n",
    "- simulation-based calibration (Talts et al. 2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8a0211",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Simulation-based calibration\n",
    "\n",
    "- a check wether the inferred posterior is well calibrated\n",
    "- using necessary conditions for valid posterior inference:\n",
    "\n",
    "\n",
    "- **condition**: Suppose we have many separate observations $x_o^i$ simulated from parameters $\\theta_o^i$. If we run the inference for each of them and obtain posterior samples $\\theta^i \\sim p(\\theta | x_o^i)$, then the these samples (across different $x_o$) are distributed according to the prior! \n",
    "\n",
    "- **check**: repeat the inference for many $x_o^i$ and compute the rank of the corresponding $\\theta_o^i$ under a set of generated posterior samples $\\{\\theta_j, \\ldots, \\theta_L\\} \\sim p(\\theta | x_o^i)$. Check whether the ranks are distributed uniformly (for every posterior dimension separately)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9654ecc2",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"figures/SBC-algorithm.png\" align=\"center\" alt=\"beadexample\" width=\"1200\"/> \n",
    "\n",
    "<img src=\"figures/SBC-ranking-formula.png\" align=\"center\" alt=\"beadexample\" width=\"600\"/> \n",
    "\n",
    "Talts et al. 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba1304c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Interpretation of SBC histograms\n",
    "\n",
    "- uniformity is a necessary condition\n",
    "- can be judged visually (or with standard uniformity (frequentists) checks)\n",
    "- visual interpretation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abb60ad",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Uniform vs auto-correlated posterior sampes\n",
    "\n",
    "<img src=\"figures/SBC-plots-spikes-autocorrelation.png\" align=\"center\" alt=\"beadexample\" width=\"1200\"/> \n",
    "\n",
    "Talts et al. 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c016a19",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Inverted U-shape: over-dispersion\n",
    "\n",
    "<img src=\"figures/SBC-plots-reverted-U-shape-overdispersion.png\" align=\"center\" alt=\"beadexample\" width=\"1200\"/> \n",
    "Talts et al. 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ef041d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## U-shape: under-dispersion\n",
    "\n",
    "<img src=\"figures/SBC-plots-U-shape-underdispersion.png\" align=\"center\" alt=\"beadexample\" width=\"1200\"/> \n",
    "Talts et al. 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc97fee",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Skewed: biased posterior\n",
    "\n",
    "<img src=\"figures/SBC-plots-skewed-bias.png\" align=\"center\" alt=\"beadexample\" width=\"1200\"/> \n",
    "Talts et al. 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1418fe9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Practical: Bayesian workflow in `sbi`\n",
    "\n",
    "### Tasks\n",
    "1) Take one the previous inference problems (linear Gaussian, two-moons, ...) and perform as much of the Bayesian workflow as possible using `sbi`\n",
    "- prior predictive checks\n",
    "- convergence diagnostics\n",
    "- posterior predictive checks\n",
    "- [optional] implement and run simulation-based calibration\n",
    "\n",
    "2) Is the inference you performed valid? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391aedcd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Discussing open questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d321bb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## References\n",
    "\n",
    "- Gelman et al. 2020, \"Bayesian workflow\", \n",
    "https://arxiv.org/abs/2011.01808\n",
    "\n",
    "- Michael Betancourt, \"Towards a principled Bayesian Workflow\", 2020\n",
    "https://betanalpha.github.io/assets/case_studies/principled_bayesian_workflow.html\n",
    "\n",
    "\n",
    "- Talts et al. 2018 \"Validating Bayesian Inference Algorithms with Simulation-Based Calibration\", https://arxiv.org/abs/1804.06788"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47958845",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
